{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firm dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the data files\n",
    "data_firm = pd.read_stata('Data/Intermediate/data_firm.dta')\n",
    "data_fred = pd.read_stata('Data/Intermediate/fred_mapped.dta')\n",
    "data_BDSe = pd.read_stata('Data/Intermediate/entry_out.dta')\n",
    "data_BEA = pd.read_stata('Data/Intermediate/BEA_industry.dta')\n",
    "data_licn = pd.read_stata('Data/Intermediate/license_out.dta')\n",
    "data_cens = pd.read_stata('Data/Intermediate/cencon_out.dta')\n",
    "data_spread = pd.read_stata('Data/Intermediate/spread_data.dta')\n",
    "data_reg = pd.read_stata('Data/Intermediate/regindex_out.dta')\n",
    "data_hhi = pd.read_stata('Data/Intermediate/mod_HHI_BEA.dta')\n",
    "\n",
    "# Perform all the merges\n",
    "data = data_firm.merge(data_fred,   how = 'outer', on = 'year')\\\n",
    "                .merge(data_BDSe,   how = 'outer', on = 'year')\\\n",
    "                .merge(data_BEA,    how = 'outer', on = ['year', 'indcode'])\\\n",
    "                .merge(data_licn,   how = 'outer', on = 'indcode')\\\n",
    "                .merge(data_cens,   how = 'outer', on = ['year', 'indcode'])\\\n",
    "                .merge(data_spread, how = 'outer', on = ['year', 'indcode'])\\\n",
    "                .merge(data_reg,    how = 'outer', on = ['year', 'indcode'])\\\n",
    "                .merge(data_hhi,    how = 'outer', on = ['year', 'indcode'])\\\n",
    "\n",
    "# Rename stuff (we are skipping adding, as we have already done it)\n",
    "data.rename(columns = {'herf_mod': 'mherf', 'herf_votmod': 'mherf_vot'}, inplace = True)\n",
    "\n",
    "# Herfs\n",
    "data['herf_adj'] = data['mherf'] - data['herf_s']\n",
    "\n",
    "# Just drop indcode or gvkey NAa\n",
    "data.dropna(subset = ['gvkey', 'indcode'], inplace = True)\n",
    "\n",
    "# Order data\n",
    "data.sort_values(['indcode', 'year'], inplace = True)\n",
    "\n",
    "# Save temporarily firm dataset\n",
    "data_firm = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count for industry/year\n",
    "data['a1_count'] = data.groupby(['indcode', 'year'])['gvkey'].transform('count')\n",
    "\n",
    "# Drop duplicates (industry only)\n",
    "data = data.drop_duplicates(subset = ['indcode', 'year']).drop(columns = ['gvkey'])\\\n",
    "           .reset_index(drop = True)\n",
    "\n",
    "# Order data\n",
    "data.sort_values(['indcode', 'year'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns which will be used to ensure proper lag shifting/conditions\n",
    "count_ok = data['a1_count'] > 5\n",
    "shift_ok = data['indcode'] == data['indcode'].shift(1) \n",
    "\n",
    "# Current columns\n",
    "columns_curr = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eval('''\n",
    "a1_q = a1_mv/a1_at \n",
    "a1_qadj = a1_mvadj/a1_atadj\n",
    "a1_ca = a1_che/a1_at \n",
    "a1_blev = a1_bliab/a1_at\n",
    "a1_paya  = a1_pay/a1_at\n",
    "a1_payos  = a1_pay/a1_os_cp\n",
    "a1_bba  = a1_bb/a1_at \n",
    "a1_bbos  = a1_bb/a1_os_cp\n",
    "a1_xrdat  = a1_xrd/a1_at\n",
    "a1_gwa = a1_gdwl/a1_at \n",
    "a1_intanat = a1_intan/a1_at\n",
    "a1_intanexgwat = (a1_intan-a1_gdwl)/a1_at \n",
    "a1_nblev = (a1_bliab - a1_che)/a1_at \n",
    "a1_txdba = a1_txdb/a1_at\n",
    "\n",
    "a1_osk_cp = a1_os_cp/a1_kdef1 \n",
    "''', inplace = True)\n",
    "\n",
    "columns_all = data.columns\n",
    "columns_new = list(set(columns_all) - set(columns_curr))\n",
    "data.loc[~shift_ok, columns_new] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eval('''\n",
    "a1_cfat = a1_cf/a1_at.shift(1) \n",
    "a1_cfk1 = a1_cf/a1_kdef1.shift(1)\n",
    "a1_cfk2 = a1_cf/a1_kdef2.shift(1)\n",
    "\n",
    "a1_ik1 = a1_inv1/a1_kdef1.shift(1)\n",
    "a1_ik3 = a1_inv3/a1_kdef3.shift(1)\n",
    "a1_ik4 = a1_inv4/a1_kdef4.shift(1)\n",
    "a1_ik5 = a1_inv5/a1_kdef5.shift(1)\n",
    "\n",
    "a1_nik1 = (a1_inv1-a1_dp1)/a1_kdef1.shift(1) \n",
    "a1_nik2 = (a1_inv2-a1_dp2)/a1_kdef2.shift(1) \n",
    "a1_nik3 = (a1_inv3-a1_dp3)/a1_kdef3.shift(1) \n",
    "a1_nik4 = (a1_inv4-a1_dp4)/a1_kdef4.shift(1) \n",
    "a1_nik5 = (a1_inv5-a1_dp5)/a1_kdef5.shift(1) \n",
    "a1_nik6 = (a1_inv6-a1_dp6)/a1_kdef6.shift(1) \n",
    "''', inplace = True)\n",
    "\n",
    "# Get all new columns, extract just newley created ones, apply a1_count > 5\n",
    "columns_all = data.columns\n",
    "columns_new = list(set(columns_all) - set(columns_curr))\n",
    "data.loc[~count_ok, columns_new] = None\n",
    "\n",
    "# Reset current columns\n",
    "columns_curr = columns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eval('''\n",
    "a1_defat = a1_findef/a1_at.shift(1)\n",
    "a1_diat = a1_ndebtiss/a1_at.shift(1)\n",
    "a1_eiat = a1_neqiss/a1_at.shift(1)\n",
    "a1_divat = a1_dv/a1_at.shift(1)\n",
    "a1_invdefat = a1_inv_def/a1_at.shift(1)\n",
    "a1_dwcat = a1_dnwc_def/a1_at.shift(1)\n",
    "\n",
    "a1_ibcat = a1_ibc/a1_at.shift(1)\n",
    "a1_xidocat = a1_xidoc/a1_at.shift(1)\n",
    "a1_dpcat = a1_dpc/a1_at.shift(1)\n",
    "a1_txdcat = a1_txdc/a1_at.shift(1)\n",
    "a1_cfotherat = a1_cfother/a1_at.shift(1)\n",
    "''', inplace = True)\n",
    "\n",
    "# Make sure shifting is ok (all vars above used shifting)\n",
    "columns_all = data.columns\n",
    "columns_new = list(set(columns_all) - set(columns_curr))\n",
    "data.loc[~shift_ok, columns_new] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eval('''\n",
    "a1_logemp = log(a1_emp) \n",
    "a1_logq = log(a1_q)\n",
    "a1_logppe = log(a1_ppe)\n",
    "\n",
    "a1_dfpct = a1_ndebtiss/a1_findef\n",
    "a1_efpct = a1_neqiss/a1_findef\n",
    "a1_dfpct2 = a1_diat/a1_defat\n",
    "a1_efpct2 = a1_eiat/a1_defat\n",
    "a1m_dfpct2 = a1m_diat/a1m_defat\n",
    "a1m_efpct2 = a1m_eiat/a1m_defat\n",
    "\n",
    "a1_dd1d = a1_dd1/a1_ltd\n",
    "a1_dd3d = a1_dd3c/a1_ltd\n",
    "a1_dd5d = a1_dd5c/a1_ltd\n",
    "\n",
    "a1_extfindep_rz = (a1_capx - a1_cf_rz) / a1_capx\n",
    "a1_exteqfindep_rz = a1_neqiss / a1_capx\n",
    "a1_extdebtfindep_rz = a1_ndebtiss / a1_capx\n",
    "a1_pifo_sh = a1_pifo/a1_pi\n",
    "\n",
    "a1_s3logN = a1_logN.diff(3)\n",
    "''', inplace = True)\n",
    "\n",
    "# Last var uses 3 period diff, correct for that\n",
    "d3_ok = data['indcode'] == data['indcode'].shift(3)\n",
    "data.loc[~d3_ok, 'a1_s3logN'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some winsor stuff\n",
    "vars_w = '''a1_paya a1_bba a1_intanat a1_xrdat a1_bbos a1_payos a1_defat a1_diat a1_eiat\n",
    " a1_dfpct a1_efpct a1_extfindep_rz a1_exteqfindep_rz a1_extdebtfindep_rz a1_pifo_sh'''\n",
    "\n",
    "for var in str_to_list(vars_w):\n",
    "    data[var] = data.groupby('year')[var].transform(winsor, l = 0.01, u = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.eval('''\n",
    "a_q = a_mv/a_at\n",
    "a_qadj = a_mvadj/a_atadj\n",
    "a_blev = a_bliab/a_at\n",
    "a_paya  = a_pay/a_at\n",
    "a_bba  = a_bb/a_at\n",
    "a_intanat  = a_intan/a_at\n",
    "a_intanexgwat  = (a_intan-a_gdwl)/a_at \n",
    "''', inplace = True)\n",
    "\n",
    "# Correction\n",
    "data.loc[~count_ok, 'a_intanexgwat'] = None\n",
    "\n",
    "# Reset current columns\n",
    "columns_curr = columns_all\n",
    "\n",
    "data.eval('''\n",
    "a_ik1 = a_inv1/a_kdef1.shift(1) \n",
    "a_ik2 = a_inv2/a_kdef2.shift(1) \n",
    "a_niat1 = (a_inv1-a_dp1)/a_at.shift(1) \n",
    "a_nik1 = (a_inv1-a_dp1)/a_kdef1.shift(1) \n",
    "a_nik2 = (a_inv2-a_dp2)/a_kdef2.shift(1) \n",
    "a_ios_cp1 = a_inv1/a_os_cp.shift(1) \n",
    "a_ios_cp2 = a_inv2/a_os_cp.shift(1)\n",
    "a_osk_cp1 = a_os_cp/a_kdef1.shift(1)\n",
    "a_osk_cp2 = a_os_cp/a_kdef2.shift(1)\n",
    "\n",
    "a_iv1 = a_inv1/a_mv.shift(1)\n",
    "a_iv2 = a_inv2/a_mv.shift(1)\n",
    "\n",
    "a_defat = a_findef/a_at.shift(1)\n",
    "a_diat = a_ndebtiss/a_at.shift(1)\n",
    "a_eiat = a_neqiss/a_at.shift(1)\n",
    "a_divat = a_dv/a_at.shift(1)\n",
    "a_invdefat = a_inv_def/a_at.shift(1)\n",
    "a_dwcat = a_dnwc_def/a_at.shift(1)\n",
    "''', inplace = True)\n",
    "\n",
    "# Make sure shifting is ok (all vars above used shifting)\n",
    "columns_all = data.columns\n",
    "columns_new = list(set(columns_all) - set(columns_curr))\n",
    "data.loc[~shift_ok, columns_new] = None\n",
    "\n",
    "data.eval('''\n",
    "a_dfpct = a_ndebtiss/a_findef\n",
    "a_efpct = a_neqiss/a_findef\n",
    "a_dfpct2 = a_diat/a_defat\n",
    "a_efpct2 = a_eiat/a_defat\n",
    "am_dfpct2 = am_diat/am_defat\n",
    "am_efpct2 = am_eiat/am_defat\n",
    "\n",
    "a_extfin = a_diat + a_eiat\n",
    "am_extfin = am_diat + am_eiat\n",
    "a_cdat = a_dv/a_at.shift(1)\n",
    "''', inplace = True)\n",
    "\n",
    "# Correct shifting\n",
    "data.loc[~shift_ok, 'a_cdat'] = None\n",
    "\n",
    "# Herfindals\n",
    "gby_y = data.groupby('year')\n",
    "\n",
    "data['amean_herf'] = gby_y['herf_s'].transform('mean')\n",
    "data['amean_mherf'] = gby_y['mherf'].transform('mean')\n",
    "data['amed_herf'] = gby_y['herf_s'].transform('median')\n",
    "data['amed_mherf'] = gby_y['mherf'].transform('median')\n",
    "\n",
    "wt_a = lambda x: pd.Series({\n",
    "    'awtmean_herf': wt_mean(x['herf_s'], weights = x['a1_sale']),\n",
    "    'awtmean_mherf': wt_mean(x['mherf'], weights = x['a1_sale'])\n",
    "})\n",
    "\n",
    "data = data.merge(gby_y.apply(wt_a), right_index = True, left_on = 'year')\n",
    "\n",
    "# Coverage metrics\n",
    "data.eval('''\n",
    "a1_niv = a1_nik_all_bea/a1_mv.shift(1)\n",
    "a_niv1 = a_nik_all_bea/a_mv.shift(1) \n",
    "a_payos = a_pay/a_os_bea\n",
    "a_bbos = a_bb/a_os_bea\n",
    "\n",
    "a1c_ppek = a1_ppe/(1000*a1_kp_all_bea)\n",
    "a1c_inv = a1_inv1/(1000*a1_kp_all_bea)\n",
    "''', inplace = True)\n",
    "\n",
    "# Fix shift and count\n",
    "data.loc[~shift_ok, ['a1_niv', 'a_niv1']] = None\n",
    "data.loc[~count_ok, ['a1_niv']] = None\n",
    "\n",
    "# Clip\n",
    "data['a1c_ppek'] = data['a1c_ppek'].clip(upper = 1) \n",
    "data['a1c_inv'] = data['a1c_inv'].clip(upper = 1) \n",
    "\n",
    "# Mean by industry\n",
    "data['avga1c_ppek'] = data.query('year > 200').groupby('indcode')['a1c_ppek'].transform('mean')\n",
    "data['avga1c_inv'] = data.query('year > 200').groupby('indcode')['a1c_inv'].transform('mean')\n",
    "\n",
    "# Dividing produced some np.infs, replace with NA\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "\n",
    "# Save as ind dataset\n",
    "data.to_stata('Data/Final/main_dataset_ind_BEA.dta', write_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns starting with a or contiang href, except firm specific ones\n",
    "ind_cols = ['at', 'act', 'aqc', 'apalch', 'aoloch', 'aldo', 'ap', 'age', 'at_l', 'aqcind', 'aldoat', 'aqcat']\n",
    "c = pd.Series(list(set(data.columns) - set(ind_cols)))\n",
    "c = c[c.str.contains(r'^a.*|.*herf.*')]\n",
    "\n",
    "# Update firm columns\n",
    "data = data_firm.merge(data[list(c) + ['indcode', 'year']], on = ['indcode', 'year'])\n",
    "\n",
    "# Keep only new columns\n",
    "cx = data.columns[data.columns.str.contains(r'_x')]\n",
    "cy = data.columns[data.columns.str.contains(r'_y')]\n",
    "\n",
    "data.drop(columns = cx, inplace = True)\n",
    "\n",
    "rename = {}\n",
    "for x in cy:\n",
    "    rename[x] = x[:-2]\n",
    "    \n",
    "data.rename(columns = rename, inplace = True)\n",
    "\n",
    "# Save\n",
    "data.to_stata('Data/Final/main_dataset_firm_BEA.dta', write_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Rename images\n",
    "for file in os.listdir('Figures'):\n",
    "    new_name = file.split('_')[0] + '.eps'\n",
    "    \n",
    "    os.rename('Figures/' + file, 'Figures/' + new_name)\n",
    "    #print(new_name)\n",
    "\n",
    "# Rename tables\n",
    "for file in os.listdir('Tables'):\n",
    "    file_parts = file.split('_')\n",
    "    \n",
    "    new_name = file_parts[0]\n",
    "    new_suffix = file_parts[-1].split('.')[-1]\n",
    "    new_file = new_name + '.' + new_suffix\n",
    "    \n",
    "    #print(new_file)\n",
    "    os.rename('Tables/' + file, 'Tables/' + new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
